{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNO3kBi54DHg2Y0w4BVB+6j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronbragaglia/An-lise-Automatizada-de-Documentos-com-Azure-AI-e-Machine-Learning/blob/main/An%C3%A1lise_Automatizada_de_Documentos_com_Azure_AI_e_Machine_Learning_para_Detec%C3%A7%C3%A3o_de_Fraudes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install azure-ai-formrecognizer pyzbar opencv-python-headless pandas scikit-learn joblib\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"AZURE_FORM_RECOGNIZER_ENDPOINT\"] = \"https://SEU_ENDPOINT.cognitiveservices.azure.com/\"\n",
        "os.environ[\"AZURE_FORM_RECOGNIZER_KEY\"] = \"SUA_CHAVE\"\n",
        "\n",
        "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "endpoint = os.environ[\"AZURE_FORM_RECOGNIZER_ENDPOINT\"]\n",
        "key = os.environ[\"AZURE_FORM_RECOGNIZER_KEY\"]\n",
        "\n",
        "document_analysis_client = DocumentAnalysisClient(\n",
        "    endpoint=endpoint,\n",
        "    credential=AzureKeyCredential(key)\n",
        ")\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "file_path = list(uploaded.keys())[0]\n",
        "print(f\"📄 Documento carregado: {file_path}\")\n",
        "\n",
        "with open(file_path, \"rb\") as fd:\n",
        "    poller = document_analysis_client.begin_analyze_document(\"prebuilt-document\", document=fd)\n",
        "result = poller.result()\n",
        "\n",
        "texto_documento = \" \".join([line.content for page in result.pages for line in page.lines])\n",
        "print(\"🔹 Texto extraído:\")\n",
        "print(texto_documento[:500], \"...\")\n",
        "\n",
        "\n",
        "import cv2\n",
        "from pyzbar.pyzbar import decode\n",
        "\n",
        "def verificar_autenticidade(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        return False\n",
        "    qrcodes = decode(img)\n",
        "    return bool(qrcodes)\n",
        "\n",
        "autenticidade = verificar_autenticidade(file_path)\n",
        "print(\"✅ QR Code detectado!\" if autenticidade else \"⚠️ Sem QR Code detectado.\")\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "palavras_suspeitas = [\"falso\", \"teste\", \"fake\", \"invalidado\"]\n",
        "tem_palavra_suspeita = int(any(p in texto_documento.lower() for p in palavras_suspeitas))\n",
        "\n",
        "features_doc = pd.DataFrame([{\n",
        "    \"tamanho_texto\": len(texto_documento),\n",
        "    \"tem_qrcode\": int(autenticidade),\n",
        "    \"tem_palavra_suspeita\": tem_palavra_suspeita\n",
        "}])\n",
        "\n",
        "print(\"🔹 Features extraídas:\")\n",
        "print(features_doc)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "X_train = np.array([\n",
        "    [500, 1, 0],\n",
        "    [300, 0, 1],\n",
        "    [800, 1, 0],\n",
        "    [200, 0, 1],\n",
        "    [1000, 1, 0]\n",
        "])\n",
        "y_train = np.array([0, 1, 0, 1, 0])\n",
        "\n",
        "modelo_fraude = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelo_fraude.fit(X_train, y_train)\n",
        "\n",
        "joblib.dump(modelo_fraude, \"modelo_fraude.joblib\")\n",
        "\n",
        "\n",
        "modelo_fraude = joblib.load(\"modelo_fraude.joblib\")\n",
        "score_fraude = modelo_fraude.predict_proba(features_doc)[0][1]\n",
        "risco_fraude = \"Suspeito de Fraude\" if score_fraude > 0.5 else \"Autêntico\"\n",
        "\n",
        "print(f\"\\n🔹 Score de Fraude: {score_fraude:.2f}\")\n",
        "print(f\"🔹 Classificação Final: {risco_fraude}\")\n",
        "\n",
        "\n",
        "df_log = pd.DataFrame([{\n",
        "    \"Documento\": file_path,\n",
        "    \"Autenticidade_QR\": autenticidade,\n",
        "    \"Score_Fraude\": round(score_fraude, 2),\n",
        "    \"Classificacao_Final\": risco_fraude\n",
        "}])\n",
        "\n",
        "df_log.to_csv(\"log_resultado_avancado.csv\", index=False)\n",
        "print(\"📄 Log salvo como log_resultado_avancado.csv\")\n"
      ],
      "metadata": {
        "id": "jkO6sXXjG-0B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}